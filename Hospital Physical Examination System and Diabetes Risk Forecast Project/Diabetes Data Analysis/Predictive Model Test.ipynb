{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e7b750-20bf-49b6-a27a-50057f019c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "train = pd.read_csv(\"C:/Users/lenovo/Desktop/d_train_20180102.csv\",encoding=\"GB2312\")\n",
    "print(train.head())\n",
    "\n",
    "# 设置pandas的显示选项，以控制DataFrame的显示格式 \n",
    "# 最大行数设置为10，以避免显示过多的数据而使结果混乱  \n",
    "pd.set_option('display.max_rows', 10)\n",
    "# 最大列数设置为10，以避免显示过多的列而使结果混乱  \n",
    "pd.set_option('display.max_columns', 10)\n",
    "# 设置每行的显示宽度为1000字符，这有助于更好地查看数据\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "data = pd.read_csv(\"C:/Users/lenovo/Desktop/d_train_20180102.csv\",encoding=\"GB2312\")\n",
    "# 打印\"train\" DataFrame的前五行，以查看数据的初步情况  \n",
    "data.head(5)\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import mpl\n",
    "## 统计\"data\" DataFrame中的重复行数量，并打印结果\n",
    "print(\"共有重复行：\", data.duplicated().sum())  #统计重复值\n",
    "# 检查\"data\" DataFrame中哪些列包含缺失值（NaN），并打印结果\n",
    "print(data.isnull().any())  # 判断哪些列包含缺失值\n",
    "# 统计\"data\" DataFrame中每列缺失值的数量，并打印结果\n",
    "print(data.isnull().sum())  # 判断每列缺失值的数量\n",
    "# 将缺失值统计结果存储在名为\"missdata\"的变量中  \n",
    "missdata = data.isnull().sum()\n",
    "# 使用describe()方法对\"missdata\"进行描述性统计，并打印结果（包括计数、平均值、标准差等）  \n",
    "print(round(missdata.describe()))  #统计缺失值\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4cb5d2-e23b-4fee-8355-eb0fe70b4028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示各特征缺失比例\n",
    "null_percentage = (data.isnull().sum() / len(data)).apply(lambda x: '{:.2%}'.format(x))  # 计算每列缺失比例\n",
    "print (null_percentage)\n",
    "# 查看血糖值是否有非均衡性的共性\n",
    "sns.set()# 使用seaborn的默认主题设置  \n",
    "ax = sns.histplot(data[\"血糖\"], kde=False, bins=300) # 使用seaborn的histplot函数绘制血糖值的直方图，kde参数为False表示不绘制核密度估计，bins参数设定了直方图的柱子数量 \n",
    "ax.set_title(\"血糖数据直方图\")\n",
    "ax.set_xlabel(\"血糖值\")\n",
    "ax.set_ylabel(\"比例\")\n",
    "\n",
    "total_samples = len(data[\"血糖\"])# 计算血糖值的样本总数  \n",
    "relative_frequencies = (ax.get_yticks() / total_samples) * 100# 计算直方图中每个柱子的相对频率（即该柱子的高度/样本总数）并乘以100得到百分比形式  \n",
    "# 将y轴标签设置为百分比格式  \n",
    "# 将y轴标签设置为百分比格式\n",
    "ax.set_yticks(ax.get_yticks())\n",
    "ax.set_yticklabels([f\"{freq:.2f}%\" for freq in relative_frequencies])\n",
    "\n",
    "plt.xlim(0, 18)# 设置x轴的显示范围为0到18  \n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] # 设置matplotlib的字体为'SimHei'，以便能够正常显示中文标签  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dfe7b7-532c-49f4-87b8-c56e62b47f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取训练数据集，使用GB2312编码格式解码  \n",
    "train = pd.read_csv(\"C:/Users/lenovo/Desktop/d_train_20180102.csv\",encoding=\"GB2312\")\n",
    "# 测试集\n",
    "test = pd.read_csv(\"C:/Users/lenovo/Desktop/d_train_20180102.csv\",encoding=\"GB2312\")\n",
    "# 删除训练集缺失率过大特征、无效的时间特征\n",
    "del_feat=['乙肝表面抗原', '乙肝表面抗体', '乙肝e抗原', '乙肝e抗体', '乙肝核心抗体', '体检日期']\n",
    "# 创建一个空列表，用于存储除删除特征外的其他特征列名  \n",
    "feat=[]\n",
    "# 遍历训练数据集的所有特征列\n",
    "for i in train.columns:\n",
    "    # 如果特征列不在删除特征列表中，则将其添加到feat列表中 \n",
    "    if i not in del_feat:\n",
    "        feat.append(i)\n",
    "\n",
    "# 根据feat列表重新选择训练数据集的特征列  \n",
    "train=train[feat]\n",
    "\n",
    "#中值补充缺实值\n",
    "medians = train.median()\n",
    "train = train.fillna(medians)\n",
    "\n",
    "\n",
    "# 将\"Outcome\"列从训练数据集中分离出来作为目标变量y，其他列作为特征x  \n",
    "y_train = train[\"Outcome\"]\n",
    "x_train = train.drop(['id','Outcome'], axis=1)\n",
    "x_test = test.drop(['id','Outcome'], axis=1)\n",
    "\n",
    "# 用平均值代替缺失值\n",
    "x_train = x_train.fillna(x_train.mean())\n",
    "x_test = x_test.fillna(x_test.mean())\n",
    "data = x_train\n",
    "null_percentagee = (data.isnull().sum() / len(data)).apply(lambda x: '{:.2%}'.format(x))  # 计算每列缺失比例\n",
    "print (null_percentagee)\n",
    "\n",
    "# 获取特征列的名称列表  \n",
    "feat_names = x_train.columns\n",
    "\n",
    "\n",
    "# 数据标准化\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # 初始化特征的标准化器\n",
    "# ss_x = StandardScaler()\n",
    "# # 分别对训练和测试数据的特征进行标准化处理\n",
    "# x_train = ss_x.fit_transform(x_train)\n",
    "#存为csv格式\n",
    "# 将处理后的训练数据集转换为CSV格式并保存到指定路径  \n",
    "x_train = pd.DataFrame(columns = feat_names, data = x_train)\n",
    " \n",
    "train = pd.concat([x_train, y_train], axis = 1)\n",
    " \n",
    "train.to_csv('C:/Users/lenovo/Desktop/pima2-diabetes.csv',index = False,header=True)# 将处理后的数据保存为CSV文件，不包含索引，包含表头\n",
    " \n",
    "print(train.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67553927-66e0-4751-a222-b6f7dfdf73a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 数据标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 初始化特征的标准化器\n",
    "ss_x = StandardScaler()\n",
    "\n",
    "#导入csv数据\n",
    "df = pd.read_csv(\"C:/Users/lenovo/Desktop/pima2-diabetes.csv\")\n",
    "#   x为可能导致糖尿病的因素\n",
    "x = df.drop('Outcome', axis=1)\n",
    "#   y为诊断结果，1为确诊，2为未确诊\n",
    "y = df['Outcome']\n",
    "\n",
    "#   训练数据(随机森林)\n",
    "def random_forest():\n",
    "    #   将数据标准化\n",
    "    X = df.drop('Outcome', axis=1)\n",
    "    #X = ss_x.fit_transform(X)\n",
    "    # 一共768个数据738个作为训练集，30个作为测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=600 / 5643, random_state=0)\n",
    "    # 若数值过大可以标准化，这里数值不算大，标准化后准确值较低，所以注释掉了不进行标准化\n",
    "    classifier = RandomForestClassifier(criterion='entropy', n_estimators=1000, max_depth=None, min_samples_split=10,\n",
    "                                            min_weight_fraction_leaf=0.02)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    print('随机森林准确率')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print('模型得分:{:.2f}'.format(classifier.score(X_test, y_test)))\n",
    "    y_ = np.array(y_test)\n",
    "    print('随机森林预测结果：', classifier.predict(X_test))\n",
    "    print('真实结果:         ', y_)\n",
    "    print('-------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e79acd8-050f-454f-9d5a-5fd3146430ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      年龄  *天门冬氨酸氨基转换酶  *丙氨酸氨基转换酶  *碱性磷酸酶  *r-谷氨酰基转换酶   *总蛋白    白蛋白   *球蛋白  \\\n",
      "3750  42        23.89      21.48   84.47       26.19  76.63  45.82  30.78   \n",
      "806   21        23.89      21.48   84.47       26.19  76.63  45.82  30.78   \n",
      "3983  35        23.89      21.48   84.47       26.19  76.63  45.82  30.78   \n",
      "3948  44        23.89      21.48   84.47       26.19  76.63  45.82  30.78   \n",
      "4198  58        21.51      17.63   87.48       18.93  74.50  46.86  27.64   \n",
      "...   ..          ...        ...     ...         ...    ...    ...    ...   \n",
      "5261  31        29.18      41.44   74.41       63.84  76.42  43.91  32.51   \n",
      "4340  30        22.28      38.64  110.78       32.79  75.47  47.47  28.00   \n",
      "2193  38        18.82      12.79   77.09       21.66  82.68  46.54  36.14   \n",
      "1399  30        23.89      21.48   84.47       26.19  76.63  45.82  30.78   \n",
      "1845  77        24.84      19.89   78.06       25.26  78.88  44.66  34.22   \n",
      "\n",
      "      白球比例  甘油三酯  ...  血小板计数  血小板平均体积  血小板体积分布宽度  血小板比积  中性粒细胞%  淋巴细胞%  单核细胞%  \\\n",
      "3750  1.49  1.44  ...  226.0      9.1       17.2  0.206    60.0   31.4    6.7   \n",
      "806   1.49  1.44  ...  216.0      8.9       16.3  0.192    56.7   34.3    7.3   \n",
      "3983  1.49  1.44  ...  261.0      9.9       11.5  0.260    58.2   35.2    5.1   \n",
      "3948  1.49  1.44  ...  359.0     10.1       11.4  0.360    72.0   21.8    4.2   \n",
      "4198  1.70  0.90  ...  256.0     10.5       12.7  0.270    57.6   33.3    6.9   \n",
      "...    ...   ...  ...    ...      ...        ...    ...     ...    ...    ...   \n",
      "5261  1.35  1.12  ...  312.0      8.7        8.8  0.270    61.4   26.3    5.8   \n",
      "4340  1.70  0.96  ...  208.0     10.8       12.7  0.220    56.6   35.4    6.2   \n",
      "2193  1.29  2.11  ...  349.0     10.6       12.9  0.370    66.9   27.3    4.7   \n",
      "1399  1.49  1.44  ...  274.0     10.2       11.8  0.280    74.2   20.9    4.4   \n",
      "1845  1.31  1.36  ...  255.0      9.0       16.8  0.228    63.8   29.8    5.1   \n",
      "\n",
      "      嗜酸细胞%  嗜碱细胞%    血糖  \n",
      "3750    1.3    0.6  6.60  \n",
      "806     0.9    0.8  4.34  \n",
      "3983    1.0    0.5  5.87  \n",
      "3948    1.6    0.4  5.29  \n",
      "4198    1.4    0.8  4.37  \n",
      "...     ...    ...   ...  \n",
      "5261    5.0    1.5  5.15  \n",
      "4340    1.3    0.5  5.11  \n",
      "2193    0.7    0.4  4.80  \n",
      "1399    0.4    0.1  4.59  \n",
      "1845    0.9    0.5  7.16  \n",
      "\n",
      "[100 rows x 34 columns]\n",
      "[1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1]\n",
      "决策树准确率\n",
      "[[75  3]\n",
      " [ 5 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95        78\n",
      "           1       0.85      0.77      0.81        22\n",
      "\n",
      "    accuracy                           0.92       100\n",
      "   macro avg       0.89      0.87      0.88       100\n",
      "weighted avg       0.92      0.92      0.92       100\n",
      "\n",
      "0.92\n",
      "模型得分:0.92\n",
      "决策树预测结果： [1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1]\n",
      "真实结果:          [1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1\n",
      " 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1]\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#def decision_tree():\n",
    "X = df.drop('Outcome', axis=1)\n",
    "#X = ss_x.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=100 / 5643)\n",
    "# 参数是经过测试得到的最高准确率的参数\n",
    "classifier = DecisionTreeClassifier(criterion='entropy', max_depth=3, min_weight_fraction_leaf=0.01)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(X_test)\n",
    "print(y_pred)\n",
    "print('决策树准确率')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print('模型得分:{:.2f}'.format(classifier.score(X_test, y_test)))\n",
    "y_ = np.array(y_test)\n",
    "print('决策树预测结果：', classifier.predict(X_test))\n",
    "print('真实结果:         ', y_)\n",
    "print('--------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f55bb4-e79c-4b6e-8725-b244187b84a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   训练数据（逻辑回归）\n",
    "def logistic_regression():\n",
    "    X = df.drop('Outcome', axis=1)\n",
    "    X = ss_x.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=30 / 768, random_state=0)\n",
    "    lr = LogisticRegression(random_state=0, max_iter=1000)\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    print('逻辑回归准确率')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print('模型得分:{:.2f}'.format(lr.score(X_test, y_test)))\n",
    "    y_ = np.array(y_test)\n",
    "    print('逻辑回归预测结果：', lr.predict(X_test))\n",
    "    print('真实结果:         ', y_)\n",
    "    print('--------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcd8d3c-f8dd-47e7-85b2-a17c2d7c48db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#   训练数据（KNN）寻找最佳的k值\n",
    "#def k_nn():\n",
    "X = df.drop('Outcome', axis=1)\n",
    "X = ss_x.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=30 / 768, random_state=0)\n",
    "error = []\n",
    "# 由于一开始并不清楚K取多少准确率最高，所以写了一个K为1-14的for循环，通过检查误差值来判断最合适的K值\n",
    "for k in range(1, 15):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_prediction = classifier.predict(X_test)\n",
    "    error.append(np.mean(y_prediction != y_test))\n",
    "    print('当k=', k, '时的准确率')\n",
    "    print(confusion_matrix(y_test, y_prediction))\n",
    "    print(classification_report(y_test, y_prediction))\n",
    "    print('模型得分:{:.2f}'.format(classifier.score(X_test, y_test)))\n",
    "    print('--------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a1d9e4-d48c-442a-afaf-557c1e561457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_n():\n",
    "    X = df.drop('Outcome', axis=1)\n",
    "    X = ss_x.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=30 / 768, random_state=0)\n",
    "    mlp = MLPClassifier(random_state=0, max_iter=5000)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    y_pred = mlp.predict(X_test)\n",
    "    print('Neural Network准确率')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print('模型得分:{:.2f}'.format(mlp.score(X_test, y_test)))\n",
    "    y_ = np.array(y_test)\n",
    "    print('Neural Network预测结果：', mlp.predict(X_test))\n",
    "    print('真实结果:         ', y_)\n",
    "    print('--------------------------------------------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59aca5e-249b-433e-b984-7e9414c1a693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "def xgb():\n",
    "    X = df.drop('Outcome', axis=1)\n",
    "    X = ss_x.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=30 / 768, random_state=0)\n",
    "    xgb = XGBClassifier(gamma=0, use_label_encoder=False, learning_rate=0.01, max_depth=10, n_estimators=10000, random_state=34, reg_lambda=6, reg_alpha=3, verbosity=0)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_prediction = xgb.predict(X_test)\n",
    "    print('XGBoost准确率')\n",
    "    print(confusion_matrix(y_test, y_prediction))\n",
    "    print(classification_report(y_test, y_prediction))\n",
    "    print(accuracy_score(y_test, y_prediction))\n",
    "    print('模型得分:{:.2f}'.format(xgb.score(X_test, y_test)))\n",
    "    y_ = np.array(y_test)\n",
    "    print('XGBoost预测结果：', xgb.predict(X_test))\n",
    "    print('真实结果:         ', y_)\n",
    "    print('--------------------------------------------------------------------------------------')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc9bae17-f5d8-4f24-a514-381ebe356806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 糖尿病诊断预测 -----------\n",
      "|1.输入指标              |2.退出系统              |\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "请输入你的选择:  1\n",
      "id: 1\n",
      "*天门冬氨酸氨基转换酶： 1\n",
      "*丙氨酸氨基转换酶： 1\n",
      "*碱性磷酸酶： 1\n",
      "*r-谷氨酰基转换酶： 1\n",
      "*总蛋白： 1\n",
      "白蛋白： 1\n",
      "*球蛋白： 1\n",
      "白球比例： 1\n",
      "甘油三酯： 1\n",
      "总胆固醇： 1\n",
      "高密度脂蛋白胆固醇： 1\n",
      "低密度脂蛋白胆固醇： 1\n",
      "尿素： 1\n",
      "肌酐： 1\n",
      "尿酸： 1\n",
      "白细胞计数： 1\n",
      "红细胞计数： 1\n",
      "血红蛋白： 1\n",
      "红细胞压积： 1\n",
      "红细胞平均体积： 1\n",
      "红细胞平均血红蛋白量： 1\n",
      "红细胞平均血红蛋白浓度： 1\n",
      "红细胞体积分布宽度： 1\n",
      "血小板计数： 1\n",
      "血小板平均体积： 1\n",
      "血小板体积分布宽度： 1\n",
      "血小板比积： 1\n",
      "中性粒细胞%： 1\n",
      "淋巴细胞%： 1\n",
      "单核细胞%： 1\n",
      "嗜酸细胞%： 1\n",
      "嗜碱细胞%： 1\n",
      "血糖： 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "----------- 训练模型选择 -----------\n",
      "|1.所有模型              |2.随机森林              |\n",
      "|3.决策树               |4.逻辑回归              |\n",
      "|5.KNN                  |6.连接模型              |\n",
      "|7.XGBoost              |\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "请选择模型： 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机森林准确率\n",
      "[[72  0]\n",
      " [ 8 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        72\n",
      "           1       1.00      0.71      0.83        28\n",
      "\n",
      "    accuracy                           0.92       100\n",
      "   macro avg       0.95      0.86      0.89       100\n",
      "weighted avg       0.93      0.92      0.92       100\n",
      "\n",
      "0.92\n",
      "模型得分:0.92\n",
      "随机森林预测结果： [0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0]\n",
      "真实结果:          [0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1\n",
      " 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0]\n",
      "-------------------------------------------\n",
      "决策树准确率\n",
      "[[80  2]\n",
      " [ 6 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95        82\n",
      "           1       0.86      0.67      0.75        18\n",
      "\n",
      "    accuracy                           0.92       100\n",
      "   macro avg       0.89      0.82      0.85       100\n",
      "weighted avg       0.92      0.92      0.92       100\n",
      "\n",
      "0.92\n",
      "模型得分:0.92\n",
      "决策树预测结果： [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0]\n",
      "真实结果:          [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0]\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "逻辑回归准确率\n",
      "[[71  1]\n",
      " [ 8 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        72\n",
      "           1       0.95      0.71      0.82        28\n",
      "\n",
      "    accuracy                           0.91       100\n",
      "   macro avg       0.93      0.85      0.88       100\n",
      "weighted avg       0.91      0.91      0.91       100\n",
      "\n",
      "0.91\n",
      "模型得分:0.91\n",
      "逻辑回归预测结果： [0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0]\n",
      "真实结果:          [0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1\n",
      " 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0]\n",
      "--------------------------------------------------------------------------------------\n",
      "当k= 1 时的准确率\n",
      "[[67  5]\n",
      " [20  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.93      0.84        72\n",
      "           1       0.62      0.29      0.39        28\n",
      "\n",
      "    accuracy                           0.75       100\n",
      "   macro avg       0.69      0.61      0.62       100\n",
      "weighted avg       0.73      0.75      0.72       100\n",
      "\n",
      "模型得分:0.75\n",
      "--------------------------------------------------------------------------------------\n",
      "当k= 2 时的准确率\n",
      "[[70  2]\n",
      " [26  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.97      0.83        72\n",
      "           1       0.50      0.07      0.12        28\n",
      "\n",
      "    accuracy                           0.72       100\n",
      "   macro avg       0.61      0.52      0.48       100\n",
      "weighted avg       0.67      0.72      0.63       100\n",
      "\n",
      "模型得分:0.72\n",
      "--------------------------------------------------------------------------------------\n",
      "当k= 3 时的准确率\n",
      "[[67  5]\n",
      " [24  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.93      0.82        72\n",
      "           1       0.44      0.14      0.22        28\n",
      "\n",
      "    accuracy                           0.71       100\n",
      "   macro avg       0.59      0.54      0.52       100\n",
      "weighted avg       0.65      0.71      0.65       100\n",
      "\n",
      "模型得分:0.71\n",
      "--------------------------------------------------------------------------------------\n",
      "当k= 4 时的准确率\n",
      "[[69  3]\n",
      " [26  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.96      0.83        72\n",
      "           1       0.40      0.07      0.12        28\n",
      "\n",
      "    accuracy                           0.71       100\n",
      "   macro avg       0.56      0.51      0.47       100\n",
      "weighted avg       0.63      0.71      0.63       100\n",
      "\n",
      "模型得分:0.71\n",
      "--------------------------------------------------------------------------------------\n",
      "当k= 5 时的准确率\n",
      "[[67  5]\n",
      " [26  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.93      0.81        72\n",
      "           1       0.29      0.07      0.11        28\n",
      "\n",
      "    accuracy                           0.69       100\n",
      "   macro avg       0.50      0.50      0.46       100\n",
      "weighted avg       0.60      0.69      0.62       100\n",
      "\n",
      "模型得分:0.69\n",
      "--------------------------------------------------------------------------------------\n",
      "当k= 6 时的准确率\n",
      "[[70  2]\n",
      " [28  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.97      0.82        72\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.70       100\n",
      "   macro avg       0.36      0.49      0.41       100\n",
      "weighted avg       0.51      0.70      0.59       100\n",
      "\n",
      "模型得分:0.70\n",
      "--------------------------------------------------------------------------------------\n",
      "当k= 7 时的准确率\n",
      "[[68  4]\n",
      " [27  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.94      0.81        72\n",
      "           1       0.20      0.04      0.06        28\n",
      "\n",
      "    accuracy                           0.69       100\n",
      "   macro avg       0.46      0.49      0.44       100\n",
      "weighted avg       0.57      0.69      0.60       100\n",
      "\n",
      "模型得分:0.69\n",
      "--------------------------------------------------------------------------------------\n",
      "当k= 8 时的准确率\n",
      "[[70  2]\n",
      " [28  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.97      0.82        72\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.70       100\n",
      "   macro avg       0.36      0.49      0.41       100\n",
      "weighted avg       0.51      0.70      0.59       100\n",
      "\n",
      "模型得分:0.70\n",
      "--------------------------------------------------------------------------------------\n",
      "当k= 9 时的准确率\n",
      "[[69  3]\n",
      " [28  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.96      0.82        72\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.69       100\n",
      "   macro avg       0.36      0.48      0.41       100\n",
      "weighted avg       0.51      0.69      0.59       100\n",
      "\n",
      "模型得分:0.69\n",
      "--------------------------------------------------------------------------------------\n",
      "当k= 10 时的准确率\n",
      "[[70  2]\n",
      " [28  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.97      0.82        72\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.70       100\n",
      "   macro avg       0.36      0.49      0.41       100\n",
      "weighted avg       0.51      0.70      0.59       100\n",
      "\n",
      "模型得分:0.70\n",
      "--------------------------------------------------------------------------------------\n",
      "当k= 11 时的准确率\n",
      "[[70  2]\n",
      " [27  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.97      0.83        72\n",
      "           1       0.33      0.04      0.06        28\n",
      "\n",
      "    accuracy                           0.71       100\n",
      "   macro avg       0.53      0.50      0.45       100\n",
      "weighted avg       0.61      0.71      0.61       100\n",
      "\n",
      "模型得分:0.71\n",
      "--------------------------------------------------------------------------------------\n",
      "当k= 12 时的准确率\n",
      "[[72  0]\n",
      " [28  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        72\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.72       100\n",
      "   macro avg       0.36      0.50      0.42       100\n",
      "weighted avg       0.52      0.72      0.60       100\n",
      "\n",
      "模型得分:0.72\n",
      "--------------------------------------------------------------------------------------\n",
      "当k= 13 时的准确率\n",
      "[[70  2]\n",
      " [28  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.97      0.82        72\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.70       100\n",
      "   macro avg       0.36      0.49      0.41       100\n",
      "weighted avg       0.51      0.70      0.59       100\n",
      "\n",
      "模型得分:0.70\n",
      "--------------------------------------------------------------------------------------\n",
      "当k= 14 时的准确率\n",
      "[[70  2]\n",
      " [28  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.97      0.82        72\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.70       100\n",
      "   macro avg       0.36      0.49      0.41       100\n",
      "weighted avg       0.51      0.70      0.59       100\n",
      "\n",
      "模型得分:0.70\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network准确率\n",
      "[[70  2]\n",
      " [ 7 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94        72\n",
      "           1       0.91      0.75      0.82        28\n",
      "\n",
      "    accuracy                           0.91       100\n",
      "   macro avg       0.91      0.86      0.88       100\n",
      "weighted avg       0.91      0.91      0.91       100\n",
      "\n",
      "0.91\n",
      "模型得分:0.91\n",
      "Neural Network预测结果： [0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0]\n",
      "真实结果:          [0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1\n",
      " 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0]\n",
      "--------------------------------------------------------------------------------------\n",
      "XGBoost准确率\n",
      "[[71  1]\n",
      " [ 6 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        72\n",
      "           1       0.96      0.79      0.86        28\n",
      "\n",
      "    accuracy                           0.93       100\n",
      "   macro avg       0.94      0.89      0.91       100\n",
      "weighted avg       0.93      0.93      0.93       100\n",
      "\n",
      "0.93\n",
      "模型得分:0.93\n",
      "XGBoost预测结果： [0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0]\n",
      "真实结果:          [0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1\n",
      " 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0]\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "<class 'numpy.ndarray'>\n",
      "[1]\n",
      "1\n",
      "******************************************************************\n",
      "----------- 糖尿病诊断预测 -----------\n",
      "|1.输入指标              |2.退出系统              |\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "请输入你的选择:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "感谢使用\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "# 数据标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "\n",
    "# 初始化特征的标准化器\n",
    "ss_x = StandardScaler()\n",
    "\n",
    "#导入csv数据\n",
    "df = pd.read_csv(\"C:/Users/lenovo/Desktop/pima2-diabetes.csv\")\n",
    "#   x为可能导致糖尿病的因素\n",
    "x = df.drop('Outcome', axis=1)\n",
    "#   y为诊断结果，1为确诊，2为未确诊\n",
    "y = df['Outcome']\n",
    "\n",
    "#   训练数据(随机森林)\n",
    "def random_forest():\n",
    "    #   将数据标准化\n",
    "    X = df.drop('Outcome', axis=1)\n",
    "    #X = ss_x.fit_transform(X)\n",
    "    # 一共768个数据738个作为训练集，30个作为测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=100 / 5643, random_state=0)\n",
    "    # 若数值过大可以标准化，这里数值不算大，标准化后准确值较低，所以注释掉了不进行标准化\n",
    "    classifier = RandomForestClassifier(criterion='entropy', n_estimators=1000, max_depth=None, min_samples_split=10,\n",
    "                                            min_weight_fraction_leaf=0.02)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    print('随机森林准确率')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print('模型得分:{:.2f}'.format(classifier.score(X_test, y_test)))\n",
    "    y_ = np.array(y_test)\n",
    "    print('随机森林预测结果：', classifier.predict(X_test))\n",
    "    print('真实结果:         ', y_)\n",
    "    print('-------------------------------------------')\n",
    "    joblib.dump(classifier, 'model1.pkl')\n",
    "\n",
    "\n",
    "#model1:随机\n",
    "#model2:决策\n",
    "#model3:逻辑\n",
    "#model4:k_nn\n",
    "#model5:神经网络\n",
    "#model6:xgboost\n",
    "\n",
    "\n",
    "#决策树\n",
    "def decision_tree():\n",
    "    X = df.drop('Outcome', axis=1)\n",
    "    #X = ss_x.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=100 / 5643)\n",
    "    # 参数是经过测试得到的最高准确率的参数\n",
    "    classifier = DecisionTreeClassifier(criterion='entropy', max_depth=3, min_weight_fraction_leaf=0.01)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    print('决策树准确率')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print('模型得分:{:.2f}'.format(classifier.score(X_test, y_test)))\n",
    "    y_ = np.array(y_test)\n",
    "    print('决策树预测结果：', classifier.predict(X_test))\n",
    "    print('真实结果:         ', y_)\n",
    "    print('--------------------------------------------------------------------------------------')\n",
    "    joblib.dump(classifier, 'model2.pkl')\n",
    "\n",
    "#   训练数据（逻辑回归）\n",
    "def logistic_regression():\n",
    "    X = df.drop('Outcome', axis=1)\n",
    "    #X = ss_x.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=100 / 5643, random_state=0)\n",
    "    lr = LogisticRegression(random_state=0, max_iter=1000)\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    print('逻辑回归准确率')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print('模型得分:{:.2f}'.format(lr.score(X_test, y_test)))\n",
    "    y_ = np.array(y_test)\n",
    "    print('逻辑回归预测结果：', lr.predict(X_test))\n",
    "    print('真实结果:         ', y_)\n",
    "    print('--------------------------------------------------------------------------------------')\n",
    "    joblib.dump(lr, 'model3.pkl')\n",
    "\n",
    "#   训练数据（KNN）寻找最佳的k值\n",
    "def k_nn():\n",
    "    X = df.drop('Outcome', axis=1)\n",
    "    #X = ss_x.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=100 / 5643, random_state=0)\n",
    "    error = []\n",
    "    # 由于一开始并不清楚K取多少准确率最高，所以写了一个K为1-14的for循环，通过检查误差值来判断最合适的K值\n",
    "    for k in range(1, 15):\n",
    "        classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_prediction = classifier.predict(X_test)\n",
    "        error.append(np.mean(y_prediction != y_test))\n",
    "        print('当k=', k, '时的准确率')\n",
    "        print(confusion_matrix(y_test, y_prediction))\n",
    "        print(classification_report(y_test, y_prediction))\n",
    "        print('模型得分:{:.2f}'.format(classifier.score(X_test, y_test)))\n",
    "        print('--------------------------------------------------------------------------------------')\n",
    "        joblib.dump(classifier, 'model4.pkl')\n",
    "\n",
    "#神经网络模型\n",
    "def n_n():\n",
    "    X = df.drop('Outcome', axis=1)\n",
    "    #X = ss_x.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=100 / 5643, random_state=0)\n",
    "    mlp = MLPClassifier(random_state=0, max_iter=5000)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    y_pred = mlp.predict(X_test)\n",
    "    print('Neural Network准确率')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print('模型得分:{:.2f}'.format(mlp.score(X_test, y_test)))\n",
    "    y_ = np.array(y_test)\n",
    "    print('Neural Network预测结果：', mlp.predict(X_test))\n",
    "    print('真实结果:         ', y_)\n",
    "    print('--------------------------------------------------------------------------------------')\n",
    "    joblib.dump(mlp, 'model5.pkl')\n",
    "\n",
    "#XGBOOST\n",
    "def xgb():\n",
    "    X = df.drop('Outcome', axis=1)\n",
    "    #X = ss_x.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=100 / 5643, random_state=0)\n",
    "    xgb = XGBClassifier(gamma=0, use_label_encoder=False, learning_rate=0.01, max_depth=10, n_estimators=10000, random_state=34, reg_lambda=6, reg_alpha=3, verbosity=0)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_prediction = xgb.predict(X_test)\n",
    "    print('XGBoost准确率')\n",
    "    print(confusion_matrix(y_test, y_prediction))\n",
    "    print(classification_report(y_test, y_prediction))\n",
    "    print(accuracy_score(y_test, y_prediction))\n",
    "    print('模型得分:{:.2f}'.format(xgb.score(X_test, y_test)))\n",
    "    y_ = np.array(y_test)\n",
    "    print('XGBoost预测结果：', xgb.predict(X_test))\n",
    "    print('真实结果:         ', y_)\n",
    "    print('--------------------------------------------------------------------------------------')\n",
    "    joblib.dump(xgb, 'model6.pkl')\n",
    "    \n",
    "\n",
    "#   主菜单\n",
    "def main_menu():\n",
    "    print('-' * 11, '糖尿病诊断预测', '-' * 11)\n",
    "    print('|{:20}|{:20}|'.format('1.输入指标', '2.退出系统'))\n",
    " \n",
    " \n",
    "#   选择模型菜单\n",
    "def option_menu():\n",
    "    print('-' * 11, '训练模型选择', '-' * 11)\n",
    "    print('|{:20}|{:20}|'.format('1.所有模型', '2.随机森林'))\n",
    "    print('|{:20}|{:20}|'.format('3.决策树', '4.逻辑回归'))\n",
    "    print('|{:23}|{:20}|'.format('5.KNN', '6.连接模型'))\n",
    "    print('|{:23}|'.format('7.XGBoost'))\n",
    "\n",
    " \n",
    " \n",
    "#   登出\n",
    "def logout():\n",
    "    print('感谢使用')\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    while True:\n",
    "        main_menu()\n",
    "        key = input('请输入你的选择: ')\n",
    "        if key == '1':\n",
    "            try:\n",
    "                ID = float(input('id:'))\n",
    "                Pregnancy = float(input('*天门冬氨酸氨基转换酶：'))\n",
    "                Glu = float(input('*丙氨酸氨基转换酶：'))\n",
    "                BP = float(input('*碱性磷酸酶：'))\n",
    "                ST = float(input('*r-谷氨酰基转换酶：'))\n",
    "                Ins = float(input('*总蛋白：'))\n",
    "                BMI = float(input('白蛋白：'))\n",
    "                DBF = float(input('*球蛋白：'))\n",
    "                Age = float(input('白球比例：'))\n",
    "                Aae = float(input('甘油三酯：'))\n",
    "                Abe = float(input('总胆固醇：'))\n",
    "                Ace = float(input('高密度脂蛋白胆固醇：'))\n",
    "                Ade = float(input('低密度脂蛋白胆固醇：'))\n",
    "                Aee = float(input('尿素：'))\n",
    "                Afe = float(input('肌酐：'))\n",
    "                Ahe = float(input('尿酸：'))\n",
    "                Aie = float(input('白细胞计数：'))\n",
    "                Aje = float(input('红细胞计数：'))\n",
    "                Ake = float(input('血红蛋白：'))\n",
    "                Ale = float(input('红细胞压积：'))\n",
    "                Ame = float(input('红细胞平均体积：'))\n",
    "                Ane = float(input('红细胞平均血红蛋白量：'))\n",
    "                Aoe = float(input('红细胞平均血红蛋白浓度：'))\n",
    "                Ape = float(input('红细胞体积分布宽度：'))\n",
    "                Aqe = float(input('血小板计数：'))\n",
    "                Are = float(input('血小板平均体积：'))\n",
    "                Ase = float(input('血小板体积分布宽度：'))\n",
    "                Ate = float(input('血小板比积：'))\n",
    "                Aue = float(input('中性粒细胞%：'))\n",
    "                Ave = float(input('淋巴细胞%：'))\n",
    "                Awe = float(input('单核细胞%：'))\n",
    "                Axe = float(input('嗜酸细胞%：'))\n",
    "                Aye = float(input('嗜碱细胞%：'))\n",
    "                Aze = float(input('血糖：'))\n",
    "            except:\n",
    "                print(\"不符合输入要求，请重新输入\")\n",
    "                continue\n",
    "\t\t\t# 将输入的值放在一个列表中\n",
    "            indices = [Pregnancy, Glu, BP, ST, Ins, BMI, DBF, Age,Aae,Abe,Ace,\n",
    "                      Ade,Aee,Afe,Ahe,Aie,Aje,Ake,Ale,Ame,Ane,Aoe,Ape,Aqe,Are,\n",
    "                      Ase,Ate,Aue,Ave,Awe,Axe,Aye,Aze,ID]\n",
    "            l = []\n",
    "            #indices = np.array(indices).reshape(1, -1)\n",
    "            for index in indices:\n",
    "                l.append(index)\n",
    " \n",
    "            empty_indices = {\"Pregnancies\": l[0], \"Glucose\": l[1], \n",
    "                             \"BloodPressure\": l[2], \"SkinThickness\": l[3],\n",
    "                             \"Insulin\": l[4], \"BMI\": l[5], \n",
    "                             \"DiabetesPedigreeFunction\": l[6], \"Age\": l[7],\n",
    "                             \"Aae\":l[8],\"Abe\":l[9],\"Ace\":l[10],\"Ade\":l[11],\n",
    "                             \"Aee\":l[12],\"Afe\":l[13],\"Ahe\":l[14],\"Aie\":l[15],\n",
    "                             \"Aje\":l[16],\"Ake\":l[17],\"Ale\":l[18],\"Ame\":l[19],\n",
    "                             \"Ane\":l[20],\"Aoe\":l[21],\"Ape\":l[22],\"Aqe\":l[23],\n",
    "                             \"Are\":l[24],\"Ase\":l[25],\"Ate\":l[26],\"Aue\":l[27],\n",
    "                             \"Ave\":l[28],\"Awe\":l[29],\"Axe\":l[30],\"Aye\":l[31],\n",
    "                             \"Aze\":l[32],\"ID\":l[33]\n",
    "                            }\n",
    "            data = pd.DataFrame(empty_indices, index=[0])\n",
    "            data = data.set_index('Pregnancies')\n",
    "            data.to_csv(\"new.csv\")\n",
    "            df_1 = pd.read_csv(\"new.csv\")\n",
    "            s = df_1.iloc[0]\n",
    "            s = np.array(s).reshape(1, -1)\n",
    "            print(s)\n",
    "            a = s[0]\n",
    "            print(a)\n",
    "            # 选择模型菜单\n",
    "            option_menu()\n",
    "            option = input('请选择模型：')\n",
    "            #   显示所有的训练模型结果\n",
    "            if option == '1':\n",
    "                random_forest()\n",
    "                decision_tree()\n",
    "                logistic_regression()\n",
    "                k_nn()\n",
    "                n_n()\n",
    "                xgb()\n",
    "                classifier = joblib.load('model3.pkl') \n",
    "                y_pre = classifier.predict(s)\n",
    "                print(\"------------------------------------------------------------------\")\n",
    "                print(type(y_pre))\n",
    "                print(y_pre)\n",
    "                a = y_pre[0]\n",
    "                print(a)\n",
    "                print('******************************************************************')\n",
    "            elif option == '2':\n",
    "                random_forest()\n",
    "            elif option == '3':\n",
    "                decision_tree()\n",
    "            elif option == '4':\n",
    "                logistic_regression()\n",
    "            elif option == '5':\n",
    "                k_nn()\n",
    "            elif option == '6':\n",
    "                n_n()\n",
    "            elif option == '7':\n",
    "                xgb()\n",
    "            else:\n",
    "                print('无效输入')\n",
    "                continue\n",
    "        elif key == '2':\n",
    "            logout()\n",
    "            break\n",
    "        else:\n",
    "            print('无效输入')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd854c3-19e8-451e-a392-3c6ee4d87678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
