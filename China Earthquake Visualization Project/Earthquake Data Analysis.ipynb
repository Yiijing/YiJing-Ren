{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75713b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Read the seismic dataset\n",
    "df = pd.read_excel(\"/Users/renyijing/Desktop/data/china.xls\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe4cfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the data frame to English for statistics\n",
    "df.columns = [\"id\", \"date\", \"lon\", \"lat\", \"depth\", \"type\", \"level\", \"loc\", \"incident\"]\n",
    "print(df.shape, \"\\n\", df.dtypes)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62262ff6",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb6a863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of NaN\n",
    "x = df.isnull().sum().sum()\n",
    "print(\"共有NaN：\", x)\n",
    "\n",
    "# Count the number of duplicate rows\n",
    "x = df.duplicated().sum()\n",
    "print(\"共有重复行：\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8369f16b",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc2f95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing at the time of the earthquake is accurate to the month and hour\n",
    "# Convert to time format\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "# Get the year and month\n",
    "df['month'] = df['date'].apply(lambda x: str(x)[:7])\n",
    "# Get the hour\n",
    "df['hour'] = df['date'].dt.hour\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfdc708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinate conversion, updating the corresponding latitude and longitude column in the DataFrame\n",
    "import requests\n",
    "\n",
    "longitude_list = []\n",
    "latitude_list = []\n",
    "# The latitude and longitude of Baidu map is converted to the latitude and longitude of AutoNavi map\n",
    "for i, location in enumerate(df[['lon','lat']].values):\n",
    "    location = str(location[0])+','+str(location[1])\n",
    "    url = 'https://restapi.amap.com/v3/assistant/coordinate/convert?'\n",
    "    parames = {\n",
    "        'locations':location,\n",
    "        'coordsys':'baidu',\n",
    "        'key':'2b7d8c3f14205821d7b0c591a7b7e1fb',\n",
    "        }\n",
    "    # Convert a list of strings in JSON data to a list\n",
    "    r = eval(requests.get(url, params=parames).json()['locations'])\n",
    "    # longitude\n",
    "    longitude_list.append(r[0])\n",
    "    # latitude\n",
    "    latitude_list.append(r[1])\n",
    "    print(f'\\r{i+1}',end='')\n",
    "# Add the converted latitude and longitude data to the original DataFrame    \n",
    "df['longitude'] = longitude_list\n",
    "df['latitude'] = latitude_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55ef1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Through the reverse geocoding API of AutoNavi Map, the longitude and latitude information is converted into the corresponding cities and provinces, and the corresponding columns in the DataFrame are updated\n",
    "citys = []\n",
    "provinces = []\n",
    "# Loop through the reverse geocoding\n",
    "for i, location in enumerate(df[['lon','lat']].values):\n",
    "    location = str(location[0])+','+str(location[1])\n",
    "    url = 'https://restapi.amap.com/v3/geocode/regeo?'\n",
    "    params = {\n",
    "        'location':location,\n",
    "        'key':'2b7d8c3f14205821d7b0c591a7b7e1fb',\n",
    "        'extensions':'base',\n",
    "        'batch':'false',\n",
    "        'roadlevel':0,\n",
    "        }\n",
    "    r = requests.get(url, params=params)\n",
    "    data = r.json()['regeocode']\n",
    "    city = data['addressComponent']['city']\n",
    "    province = data['addressComponent']['province']\n",
    "    if len(city)==0:\n",
    "        city = province\n",
    "    citys.append(city)\n",
    "    provinces.append(province)\n",
    "    print(f'\\r{i+1}',end='')\n",
    "# Add the obtained city and province information to the original DataFrame\n",
    "df['city'] = citys\n",
    "df['province'] = provinces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf05748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Areas that do not have a clear city or province are classified as border areas of other sea areas\n",
    "df['city'] = df['city'].replace('[]', '其他海域边境地区')\n",
    "df['city'] = df['city'].replace('中华人民共和国', '其他海域边境地区')\n",
    "df['province'] = df['province'].replace(' [] ', '其他海域边境地区')\n",
    "df['province'] = df['province'].replace('中华人民共和国','其他海域边境地区')\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8598ab",
   "metadata": {},
   "source": [
    "# Statistics and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6b3066",
   "metadata": {},
   "source": [
    "The number of earthquakes with level>=4.5 in each province from 2013 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae19653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from pyecharts.globals import SymbolType\n",
    "\n",
    "# Convert the list in the province column to a string\n",
    "df['province'] = df['province'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Filter out rows with province set to []\n",
    "df_cn = df[df['province'] != '[]']\n",
    "\n",
    "# Select a row with a seismic magnitude greater than or equal to 4.5\n",
    "df_severe = df_cn[df_cn['level'] >= 4.5]\n",
    "\n",
    "# Group by province and count the number of earthquakes in each province\n",
    "df_province = df_severe.groupby('province')['date'].count().to_frame('次数').sort_values(by='次数', ascending=False).reset_index()\n",
    "\n",
    "# Generate a word frequency dictionary\n",
    "wordcloud_data = dict(zip(df_province['province'], df_province['次数']))\n",
    "\n",
    "# Create a word cloud object\n",
    "wordcloud = WordCloud(font_path='/System/Library/Fonts/PingFang.ttc',\n",
    "                      width=800, \n",
    "                      height=400, \n",
    "                      background_color='white').generate_from_frequencies(wordcloud_data)\n",
    "# Draw a word cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] \n",
    "plt.title('2013-2020年各省份M>=4.5的地震次数', fontsize=15) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612e96a9",
   "metadata": {},
   "source": [
    "Cloud map of the top 15 cities with the number of earthquakes with M>=4.5 in each province from 2013 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d377e6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list in the city column to a string\n",
    "df['city'] = df['city'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Filter out rows where city is [].\n",
    "df_cm = df[df['city'] != '[]']\n",
    "\n",
    "# Select a row with a seismic magnitude greater than or equal to 4.5\n",
    "df_level = df_cm[df_cm['level'] >= 4.5]\n",
    "\n",
    "# Group by city and count the number of earthquakes in each city\n",
    "df_city = df_level.groupby('city')['date'].count().to_frame('次数').sort_values(by='次数', ascending=False).reset_index()\n",
    "print(df_city.head(14))\n",
    "\n",
    "# Generate a word frequency dictionary\n",
    "wordcloud_data1 = dict(zip(df_city['city'], df_city['次数']))\n",
    "\n",
    "# Create a word cloud object\n",
    "wordcloud = WordCloud(font_path='/System/Library/Fonts/PingFang.ttc',\n",
    "                      width=800, \n",
    "                      height=400, \n",
    "                      background_color='white').generate_from_frequencies(wordcloud_data1)\n",
    "# Draw a word cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] \n",
    "plt.title('2013-2020年发生M>=4.5地震次数前15城市', fontsize=15) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974f5140",
   "metadata": {},
   "source": [
    "Heat map of earthquake distribution in China from 2013 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0320e67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Filter rows with seismic magnitude greater than or equal to 4.5 and store the results in df_data\n",
    "df_data = df.query('level >= 4.5')\n",
    "\n",
    "# A Densitymapbox object is created\n",
    "my_map = go.Densitymapbox(lat=df_data['lat'], lon=df_data['lon'], z=df_data['level'], radius=10)\n",
    "fig = go.Figure(my_map)\n",
    "p1 = fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "\n",
    "\n",
    "p1.write_html(\"p1.html\", include_plotlyjs='cdn')\n",
    "p1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e12cd",
   "metadata": {},
   "source": [
    "Scatter plot of the magnitude and source depth of earthquakes in China from 2013 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc07552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract magnitude and source depth data\n",
    "level = df['level']\n",
    "depth = df['depth']\n",
    "\n",
    "# Draw a scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(level, depth, c='blue', alpha=0.5, s=6)\n",
    "\n",
    "# Add a title and axis labels\n",
    "plt.title('2013-2020年震级震源深度散点图')\n",
    "plt.xlabel('震级（M）')\n",
    "plt.ylabel('深度 (km)')\n",
    "\n",
    "# Display graphics\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841700ec",
   "metadata": {},
   "source": [
    "Number of earthquakes in 2013-2020 Nightingale Rose Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb5485b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = pd.DataFrame(df)\n",
    "df_n['month'] = pd.to_datetime(df_n['month'])\n",
    "df_n['year'] = df_n['month'].dt.year\n",
    "\n",
    "# Count the number of earthquakes by year\n",
    "yearly_counts = df_n['year'].value_counts().sort_index()\n",
    "print(yearly_counts)\n",
    "\n",
    "# Calculate the angle of each sector\n",
    "total_years = len(yearly_counts)\n",
    "angles = np.linspace(0, 2 * np.pi, total_years, endpoint=False)\n",
    "\n",
    "# Create the Nightingale Rose Diagram\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "ax.set_theta_offset(np.pi / 2)\n",
    "ax.set_theta_direction(-1)\n",
    "\n",
    "# Use a histogram to represent the number of earthquakes per year\n",
    "bars = ax.bar(angles, yearly_counts, align='center', alpha=0.7)\n",
    "\n",
    "# Set up labels\n",
    "ax.set_xticks(angles)\n",
    "ax.set_xticklabels(yearly_counts.index)\n",
    "\n",
    "plt.title('2013-2020各年分发生的地震数图')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52b726e",
   "metadata": {},
   "source": [
    "Histogram of the percentage of earthquakes occurring in a 24-hour period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0c333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h = pd.DataFrame(df)\n",
    "\n",
    "# Convert the \"date\" column to the datetime type\n",
    "df_h['date'] = pd.to_datetime(df_h['date'])\n",
    "\n",
    "# Extract hour information\n",
    "df_h['hour'] = df_h['date'].dt.hour\n",
    "\n",
    "# Count the number of earthquakes per hour\n",
    "hourly_counts = df_h['hour'].value_counts().sort_index()\n",
    "\n",
    "# Draw a histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "hourly_counts.plot(kind='bar', color='skyblue')\n",
    "        \n",
    "plt.title('24小时段地震发生次数图')\n",
    "plt.xlabel('时刻')\n",
    "plt.ylabel('发生地震次数')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38e6bbf",
   "metadata": {},
   "source": [
    "Top 10 worst earthquakes of 2013-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4db0b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l = pd.DataFrame(df)\n",
    "\n",
    "# Sort by level column in descending order\n",
    "sorted_df = df_l.sort_values(by='level', ascending=False)\n",
    "\n",
    "# Get the top ten largest items\n",
    "top_ten_items = sorted_df.head(16)\n",
    "\n",
    "# Output the result\n",
    "print(top_ten_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b55ca7",
   "metadata": {},
   "source": [
    "The number of earthquakes that occurred in each magnitude range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1a217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = pd.DataFrame(df)\n",
    "\n",
    "# Define the scope\n",
    "ranges = [1, 3, 4.5, 6, 7, 8]\n",
    "\n",
    "# Use the cut method to divide the data into different ranges\n",
    "df_a['level_range'] = pd.cut(df_a['level'], bins=ranges)\n",
    "\n",
    "# The number of counts for each range\n",
    "level_counts = df_a['level_range'].value_counts().sort_index()\n",
    "\n",
    "# Output the result\n",
    "print(level_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8d23fc",
   "metadata": {},
   "source": [
    "Statistics for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2cfa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b = pd.DataFrame(df)\n",
    "df_b['date'] = pd.to_datetime(df_b['date'])  # 将 date 列转换为 datetime 类型\n",
    "\n",
    "# Year of extraction\n",
    "df_b['year'] = df_b['date'].dt.year\n",
    "\n",
    "# Grouped by year, the number of earthquakes, the average magnitude, and the average depth are calculated each year\n",
    "result = df_b.groupby('year').agg({\n",
    "    'date': 'count',        # Number of earthquakes\n",
    "    'level': 'mean',        # Average magnitude\n",
    "    'depth': 'mean'         # Average depth\n",
    "}).reset_index()\n",
    "\n",
    "# Rename the column name\n",
    "result.columns = ['year', 'earthquake_count', 'average_level', 'average_depth']\n",
    "\n",
    "# Output the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8322f74",
   "metadata": {},
   "source": [
    "Collect earthquake depth information for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4fee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v = pd.DataFrame(df)\n",
    "\n",
    "# Count the maximum and minimum values of the depth column\n",
    "max_depth = df_v['depth'].max()\n",
    "min_depth = df_v['depth'].min()\n",
    "\n",
    "# Output the result\n",
    "print(\"最大深度:\", max_depth)\n",
    "print(\"最小深度:\", min_depth)\n",
    "\n",
    "# Define the scope\n",
    "ranges_v = [0,10,20,100,700]\n",
    "\n",
    "# Use the cut method to divide the data into different ranges\n",
    "df_v['depth_range'] = pd.cut(df_a['depth'], bins=ranges_v)\n",
    "\n",
    "# The number of counts for each range\n",
    "depth_counts = df_v['depth_range'].value_counts().sort_index()\n",
    "\n",
    "# Output the result\n",
    "print(depth_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477582a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f8a8cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
